{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-393 Máquinas de Aprendizaje II-2019 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 3 - Ensamblados y modelos avanzados </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "* Técnicas de ensamblado: *bagging*, *boosting* y *random forest*.\n",
    "* Ventajas de técnicas de ensamblados\n",
    "* Problemas desbalanceados\n",
    " \n",
    "\n",
    "**Formalidades**  \n",
    "* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
    "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
    "* Fecha de entrega y cierre competencia: 17 de Enero\n",
    "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea3-INF393-II-2019]\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Ensamblados para regresión  \n",
    "[2.](#segundo) Detección de acoso en *Twitter*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"primero\"></a>\n",
    "## 1. Ensamblados para regresión\n",
    "---\n",
    "Las técnicas de ensamblados vistos en clases pueden ser aplicadas tanto a problemas de clasificación o regresión, teniendo la ventaja de utilizar múltiples modelos de aprendizaje para utilizar la ventaja de cada uno. En este actividad se trabajará con predecir la temperatura media de un día, dada cierta información del día anterior, como la humedad, velocidad del viento, presión atmosférica, fecha y temperatura. El modelo predictor derivado puede ser bastante útil para conocer el comportamiento del clima a lo largo del tiempo.\n",
    "\n",
    "<img src=\"https://scijinks.gov/review/forecast-reliability/forecast-reliability2.jpg\" title=\"Title text\" width=\"70%\"  />\n",
    "\n",
    "Los datos de clima son recolectados en la ciudad Delhi de India por un período de 4 años (2013 a 2017), proporcionados en Kaggle a través del siguiente __[link](https://www.kaggle.com/sumanthvrao/daily-climate-time-series-data)__, las particiones de entrenamiento y prueba están dadas. El registro de cada dato corresponde a un día, incrementando a través de las filas por cada día.\n",
    "\n",
    "---\n",
    "    \n",
    ">  Cargue los datos en un dataframe de pandas, además agregue una columna indicando el valor a predecir, la temperatura media del día siguiente. *Como el último dato/registro no tiene un valor a predecir éste se elimina*.\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"DailyDelhiClimateTrain.csv\")\n",
    "df[\"y_value\"] = df[\"meantemp\"].shift(-1)\n",
    "df = df.iloc[:-1] #remove last row\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "      <th>y_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1015.666667</td>\n",
       "      <td>7.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>1017.800000</td>\n",
       "      <td>7.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>1018.666667</td>\n",
       "      <td>8.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>71.333333</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>1017.166667</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>86.833333</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1016.500000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>82.800000</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>1018.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>78.600000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>8.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>63.714286</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>1018.714286</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>51.250000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>1017.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>1015.666667</td>\n",
       "      <td>15.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-01-11</td>\n",
       "      <td>15.714286</td>\n",
       "      <td>51.285714</td>\n",
       "      <td>10.571429</td>\n",
       "      <td>1016.142857</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-01-12</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>13.228571</td>\n",
       "      <td>1015.571429</td>\n",
       "      <td>15.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>15.833333</td>\n",
       "      <td>75.166667</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>1013.333333</td>\n",
       "      <td>12.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013-01-14</td>\n",
       "      <td>12.833333</td>\n",
       "      <td>88.166667</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>1015.166667</td>\n",
       "      <td>14.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>14.714286</td>\n",
       "      <td>71.857143</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>1015.857143</td>\n",
       "      <td>13.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013-01-16</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1016.666667</td>\n",
       "      <td>16.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013-01-17</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>80.833333</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1015.833333</td>\n",
       "      <td>13.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>92.166667</td>\n",
       "      <td>8.950000</td>\n",
       "      <td>1014.500000</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013-01-19</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>5.883333</td>\n",
       "      <td>1021.666667</td>\n",
       "      <td>11.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013-01-20</td>\n",
       "      <td>11.285714</td>\n",
       "      <td>75.285714</td>\n",
       "      <td>8.471429</td>\n",
       "      <td>1020.285714</td>\n",
       "      <td>11.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2013-01-21</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>2.220000</td>\n",
       "      <td>1021.000000</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2013-01-22</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1021.800000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013-01-23</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>60.166667</td>\n",
       "      <td>4.016667</td>\n",
       "      <td>1020.500000</td>\n",
       "      <td>13.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2013-01-24</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>60.666667</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1020.500000</td>\n",
       "      <td>12.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>5.550000</td>\n",
       "      <td>1020.750000</td>\n",
       "      <td>12.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>64.166667</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>1019.666667</td>\n",
       "      <td>12.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>12.857143</td>\n",
       "      <td>65.571429</td>\n",
       "      <td>5.557143</td>\n",
       "      <td>1018.142857</td>\n",
       "      <td>14.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>14.833333</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1017.833333</td>\n",
       "      <td>14.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2013-01-29</td>\n",
       "      <td>14.125000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>3.237500</td>\n",
       "      <td>1016.625000</td>\n",
       "      <td>14.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2013-01-30</td>\n",
       "      <td>14.714286</td>\n",
       "      <td>70.428571</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>1017.857143</td>\n",
       "      <td>16.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>2016-12-02</td>\n",
       "      <td>19.208333</td>\n",
       "      <td>75.875000</td>\n",
       "      <td>4.945833</td>\n",
       "      <td>1017.750000</td>\n",
       "      <td>21.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>2016-12-03</td>\n",
       "      <td>21.208333</td>\n",
       "      <td>52.166667</td>\n",
       "      <td>5.866667</td>\n",
       "      <td>1019.333333</td>\n",
       "      <td>18.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>2016-12-04</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>55.250000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1019.700000</td>\n",
       "      <td>18.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>18.636364</td>\n",
       "      <td>56.590909</td>\n",
       "      <td>4.952381</td>\n",
       "      <td>1017.045455</td>\n",
       "      <td>18.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2016-12-06</td>\n",
       "      <td>18.538462</td>\n",
       "      <td>69.923077</td>\n",
       "      <td>2.503846</td>\n",
       "      <td>1017.961538</td>\n",
       "      <td>18.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2016-12-07</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>74.350000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>1017.421053</td>\n",
       "      <td>16.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2016-12-08</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>73.300000</td>\n",
       "      <td>1.765000</td>\n",
       "      <td>1016.200000</td>\n",
       "      <td>19.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>19.416667</td>\n",
       "      <td>68.125000</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>1013.416667</td>\n",
       "      <td>16.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2016-12-10</td>\n",
       "      <td>16.444444</td>\n",
       "      <td>82.833333</td>\n",
       "      <td>5.355556</td>\n",
       "      <td>1014.000000</td>\n",
       "      <td>20.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>2016-12-11</td>\n",
       "      <td>20.041667</td>\n",
       "      <td>69.583333</td>\n",
       "      <td>4.716667</td>\n",
       "      <td>1013.291667</td>\n",
       "      <td>19.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>2016-12-12</td>\n",
       "      <td>19.909091</td>\n",
       "      <td>63.863636</td>\n",
       "      <td>3.281818</td>\n",
       "      <td>1014.181818</td>\n",
       "      <td>19.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>2016-12-13</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>62.350000</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>1015.100000</td>\n",
       "      <td>18.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>18.555556</td>\n",
       "      <td>58.611111</td>\n",
       "      <td>8.027778</td>\n",
       "      <td>1017.333333</td>\n",
       "      <td>18.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>56.625000</td>\n",
       "      <td>9.879167</td>\n",
       "      <td>1016.666667</td>\n",
       "      <td>15.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>15.833333</td>\n",
       "      <td>63.277778</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>1018.777778</td>\n",
       "      <td>17.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>63.388889</td>\n",
       "      <td>6.731579</td>\n",
       "      <td>1016.947368</td>\n",
       "      <td>16.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>2016-12-18</td>\n",
       "      <td>16.083333</td>\n",
       "      <td>64.541667</td>\n",
       "      <td>6.420833</td>\n",
       "      <td>1018.083333</td>\n",
       "      <td>17.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>17.857143</td>\n",
       "      <td>56.095238</td>\n",
       "      <td>10.414286</td>\n",
       "      <td>1017.428571</td>\n",
       "      <td>19.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>48.533333</td>\n",
       "      <td>15.926667</td>\n",
       "      <td>1015.200000</td>\n",
       "      <td>18.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>2016-12-21</td>\n",
       "      <td>18.050000</td>\n",
       "      <td>54.300000</td>\n",
       "      <td>19.404762</td>\n",
       "      <td>1015.619048</td>\n",
       "      <td>17.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>17.285714</td>\n",
       "      <td>57.857143</td>\n",
       "      <td>6.180952</td>\n",
       "      <td>1016.142857</td>\n",
       "      <td>15.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>15.550000</td>\n",
       "      <td>74.700000</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>1014.250000</td>\n",
       "      <td>17.318182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>2016-12-24</td>\n",
       "      <td>17.318182</td>\n",
       "      <td>78.636364</td>\n",
       "      <td>5.236364</td>\n",
       "      <td>1011.318182</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2016-12-25</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>94.300000</td>\n",
       "      <td>9.085000</td>\n",
       "      <td>1014.350000</td>\n",
       "      <td>17.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2016-12-26</td>\n",
       "      <td>17.142857</td>\n",
       "      <td>74.857143</td>\n",
       "      <td>8.784211</td>\n",
       "      <td>1016.952381</td>\n",
       "      <td>16.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>67.550000</td>\n",
       "      <td>8.335000</td>\n",
       "      <td>1017.200000</td>\n",
       "      <td>17.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>17.217391</td>\n",
       "      <td>68.043478</td>\n",
       "      <td>3.547826</td>\n",
       "      <td>1015.565217</td>\n",
       "      <td>15.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>15.238095</td>\n",
       "      <td>87.857143</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1016.904762</td>\n",
       "      <td>14.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>14.095238</td>\n",
       "      <td>89.666667</td>\n",
       "      <td>6.266667</td>\n",
       "      <td>1017.904762</td>\n",
       "      <td>15.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>15.052632</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.325000</td>\n",
       "      <td>1016.100000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1461 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   meantemp   humidity  wind_speed  meanpressure    y_value\n",
       "0     2013-01-01  10.000000  84.500000    0.000000   1015.666667   7.400000\n",
       "1     2013-01-02   7.400000  92.000000    2.980000   1017.800000   7.166667\n",
       "2     2013-01-03   7.166667  87.000000    4.633333   1018.666667   8.666667\n",
       "3     2013-01-04   8.666667  71.333333    1.233333   1017.166667   6.000000\n",
       "4     2013-01-05   6.000000  86.833333    3.700000   1016.500000   7.000000\n",
       "5     2013-01-06   7.000000  82.800000    1.480000   1018.000000   7.000000\n",
       "6     2013-01-07   7.000000  78.600000    6.300000   1020.000000   8.857143\n",
       "7     2013-01-08   8.857143  63.714286    7.142857   1018.714286  14.000000\n",
       "8     2013-01-09  14.000000  51.250000   12.500000   1017.000000  11.000000\n",
       "9     2013-01-10  11.000000  62.000000    7.400000   1015.666667  15.714286\n",
       "10    2013-01-11  15.714286  51.285714   10.571429   1016.142857  14.000000\n",
       "11    2013-01-12  14.000000  74.000000   13.228571   1015.571429  15.833333\n",
       "12    2013-01-13  15.833333  75.166667    4.633333   1013.333333  12.833333\n",
       "13    2013-01-14  12.833333  88.166667    0.616667   1015.166667  14.714286\n",
       "14    2013-01-15  14.714286  71.857143    0.528571   1015.857143  13.833333\n",
       "15    2013-01-16  13.833333  86.666667    0.000000   1016.666667  16.500000\n",
       "16    2013-01-17  16.500000  80.833333    5.250000   1015.833333  13.833333\n",
       "17    2013-01-18  13.833333  92.166667    8.950000   1014.500000  12.500000\n",
       "18    2013-01-19  12.500000  76.666667    5.883333   1021.666667  11.285714\n",
       "19    2013-01-20  11.285714  75.285714    8.471429   1020.285714  11.200000\n",
       "20    2013-01-21  11.200000  77.000000    2.220000   1021.000000   9.500000\n",
       "21    2013-01-22   9.500000  79.666667    3.083333   1021.800000  14.000000\n",
       "22    2013-01-23  14.000000  60.166667    4.016667   1020.500000  13.833333\n",
       "23    2013-01-24  13.833333  60.666667    6.166667   1020.500000  12.250000\n",
       "24    2013-01-25  12.250000  67.000000    5.550000   1020.750000  12.666667\n",
       "25    2013-01-26  12.666667  64.166667    6.800000   1019.666667  12.857143\n",
       "26    2013-01-27  12.857143  65.571429    5.557143   1018.142857  14.833333\n",
       "27    2013-01-28  14.833333  56.000000    3.700000   1017.833333  14.125000\n",
       "28    2013-01-29  14.125000  65.500000    3.237500   1016.625000  14.714286\n",
       "29    2013-01-30  14.714286  70.428571    1.057143   1017.857143  16.200000\n",
       "...          ...        ...        ...         ...           ...        ...\n",
       "1431  2016-12-02  19.208333  75.875000    4.945833   1017.750000  21.208333\n",
       "1432  2016-12-03  21.208333  52.166667    5.866667   1019.333333  18.900000\n",
       "1433  2016-12-04  18.900000  55.250000    5.666667   1019.700000  18.636364\n",
       "1434  2016-12-05  18.636364  56.590909    4.952381   1017.045455  18.538462\n",
       "1435  2016-12-06  18.538462  69.923077    2.503846   1017.961538  18.250000\n",
       "1436  2016-12-07  18.250000  74.350000    0.925000   1017.421053  16.900000\n",
       "1437  2016-12-08  16.900000  73.300000    1.765000   1016.200000  19.416667\n",
       "1438  2016-12-09  19.416667  68.125000    1.312500   1013.416667  16.444444\n",
       "1439  2016-12-10  16.444444  82.833333    5.355556   1014.000000  20.041667\n",
       "1440  2016-12-11  20.041667  69.583333    4.716667   1013.291667  19.909091\n",
       "1441  2016-12-12  19.909091  63.863636    3.281818   1014.181818  19.050000\n",
       "1442  2016-12-13  19.050000  62.350000    3.430000   1015.100000  18.555556\n",
       "1443  2016-12-14  18.555556  58.611111    8.027778   1017.333333  18.166667\n",
       "1444  2016-12-15  18.166667  56.625000    9.879167   1016.666667  15.833333\n",
       "1445  2016-12-16  15.833333  63.277778    3.916667   1018.777778  17.500000\n",
       "1446  2016-12-17  17.500000  63.388889    6.731579   1016.947368  16.083333\n",
       "1447  2016-12-18  16.083333  64.541667    6.420833   1018.083333  17.857143\n",
       "1448  2016-12-19  17.857143  56.095238   10.414286   1017.428571  19.800000\n",
       "1449  2016-12-20  19.800000  48.533333   15.926667   1015.200000  18.050000\n",
       "1450  2016-12-21  18.050000  54.300000   19.404762   1015.619048  17.285714\n",
       "1451  2016-12-22  17.285714  57.857143    6.180952   1016.142857  15.550000\n",
       "1452  2016-12-23  15.550000  74.700000    1.205000   1014.250000  17.318182\n",
       "1453  2016-12-24  17.318182  78.636364    5.236364   1011.318182  14.000000\n",
       "1454  2016-12-25  14.000000  94.300000    9.085000   1014.350000  17.142857\n",
       "1455  2016-12-26  17.142857  74.857143    8.784211   1016.952381  16.850000\n",
       "1456  2016-12-27  16.850000  67.550000    8.335000   1017.200000  17.217391\n",
       "1457  2016-12-28  17.217391  68.043478    3.547826   1015.565217  15.238095\n",
       "1458  2016-12-29  15.238095  87.857143    6.000000   1016.904762  14.095238\n",
       "1459  2016-12-30  14.095238  89.666667    6.266667   1017.904762  15.052632\n",
       "1460  2016-12-31  15.052632  87.000000    7.325000   1016.100000  10.000000\n",
       "\n",
       "[1461 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"DailyDelhiClimateTrain.csv\")\n",
    "df[\"y_value\"] = df[\"meantemp\"].shift(-1)\n",
    "df = df.iloc[:-1] #remove last row\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Debido a la poca información que se tiene a través de los 4 parámetros medidos, extraíga más información a través de los datos de fecha. Por ejemplo, el comportamiento a través de los meses y años varía, así como la información de la temporada del año podría ayudar a la predicción. Decida si puede incluir más información a partir de la fecha que tenga sentido con el problema.\n",
    "```python\n",
    "...#procesamiento de fecha(datetime/timestamp) a numeros\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df['cday'] = df['date'].dt.dayofweek #0:lunes,6:domingo\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month #1:enero, 12: diciembre\n",
    "...#based on: https://en.wikipedia.org/wiki/Climate_of_India\n",
    "seasons = [\"winter\",\"winter\",\"summer\",\"summer\",\"summer\",\"rainy\",\"rainy\",\"rainy\",\"fall\",\"fall\",\"fall\",\"winter\"]\n",
    "df['season'] = [ seasons[month_i - 1] for month_i in df['month'].values ]\n",
    "df = pd.get_dummies(df,columns=['season']) #to one hot.. as nominal variable\n",
    "... #any more information?\n",
    "df.drop([\"date\"], axis=1, inplace=True) #delete date\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "      <th>y_value</th>\n",
       "      <th>cday</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>season_fall</th>\n",
       "      <th>season_rainy</th>\n",
       "      <th>season_summer</th>\n",
       "      <th>season_winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1015.666667</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.400000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>1017.800000</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.166667</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>1018.666667</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.666667</td>\n",
       "      <td>71.333333</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>1017.166667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>86.833333</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1016.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>82.800000</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>1018.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>78.600000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.857143</td>\n",
       "      <td>63.714286</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>1018.714286</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>51.250000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>1017.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>1015.666667</td>\n",
       "      <td>15.714286</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.714286</td>\n",
       "      <td>51.285714</td>\n",
       "      <td>10.571429</td>\n",
       "      <td>1016.142857</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>13.228571</td>\n",
       "      <td>1015.571429</td>\n",
       "      <td>15.833333</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.833333</td>\n",
       "      <td>75.166667</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>1013.333333</td>\n",
       "      <td>12.833333</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12.833333</td>\n",
       "      <td>88.166667</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>1015.166667</td>\n",
       "      <td>14.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.714286</td>\n",
       "      <td>71.857143</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>1015.857143</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.833333</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1016.666667</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.500000</td>\n",
       "      <td>80.833333</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1015.833333</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.833333</td>\n",
       "      <td>92.166667</td>\n",
       "      <td>8.950000</td>\n",
       "      <td>1014.500000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>5.883333</td>\n",
       "      <td>1021.666667</td>\n",
       "      <td>11.285714</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11.285714</td>\n",
       "      <td>75.285714</td>\n",
       "      <td>8.471429</td>\n",
       "      <td>1020.285714</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11.200000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>2.220000</td>\n",
       "      <td>1021.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.500000</td>\n",
       "      <td>79.666667</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1021.800000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>60.166667</td>\n",
       "      <td>4.016667</td>\n",
       "      <td>1020.500000</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13.833333</td>\n",
       "      <td>60.666667</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1020.500000</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12.250000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>5.550000</td>\n",
       "      <td>1020.750000</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.666667</td>\n",
       "      <td>64.166667</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>1019.666667</td>\n",
       "      <td>12.857143</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12.857143</td>\n",
       "      <td>65.571429</td>\n",
       "      <td>5.557143</td>\n",
       "      <td>1018.142857</td>\n",
       "      <td>14.833333</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14.833333</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1017.833333</td>\n",
       "      <td>14.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14.125000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>3.237500</td>\n",
       "      <td>1016.625000</td>\n",
       "      <td>14.714286</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14.714286</td>\n",
       "      <td>70.428571</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>1017.857143</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>19.208333</td>\n",
       "      <td>75.875000</td>\n",
       "      <td>4.945833</td>\n",
       "      <td>1017.750000</td>\n",
       "      <td>21.208333</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>21.208333</td>\n",
       "      <td>52.166667</td>\n",
       "      <td>5.866667</td>\n",
       "      <td>1019.333333</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>18.900000</td>\n",
       "      <td>55.250000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1019.700000</td>\n",
       "      <td>18.636364</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>18.636364</td>\n",
       "      <td>56.590909</td>\n",
       "      <td>4.952381</td>\n",
       "      <td>1017.045455</td>\n",
       "      <td>18.538462</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>18.538462</td>\n",
       "      <td>69.923077</td>\n",
       "      <td>2.503846</td>\n",
       "      <td>1017.961538</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>18.250000</td>\n",
       "      <td>74.350000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>1017.421053</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>16.900000</td>\n",
       "      <td>73.300000</td>\n",
       "      <td>1.765000</td>\n",
       "      <td>1016.200000</td>\n",
       "      <td>19.416667</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>19.416667</td>\n",
       "      <td>68.125000</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>1013.416667</td>\n",
       "      <td>16.444444</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>16.444444</td>\n",
       "      <td>82.833333</td>\n",
       "      <td>5.355556</td>\n",
       "      <td>1014.000000</td>\n",
       "      <td>20.041667</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>20.041667</td>\n",
       "      <td>69.583333</td>\n",
       "      <td>4.716667</td>\n",
       "      <td>1013.291667</td>\n",
       "      <td>19.909091</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>19.909091</td>\n",
       "      <td>63.863636</td>\n",
       "      <td>3.281818</td>\n",
       "      <td>1014.181818</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>19.050000</td>\n",
       "      <td>62.350000</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>1015.100000</td>\n",
       "      <td>18.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>18.555556</td>\n",
       "      <td>58.611111</td>\n",
       "      <td>8.027778</td>\n",
       "      <td>1017.333333</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>18.166667</td>\n",
       "      <td>56.625000</td>\n",
       "      <td>9.879167</td>\n",
       "      <td>1016.666667</td>\n",
       "      <td>15.833333</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>15.833333</td>\n",
       "      <td>63.277778</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>1018.777778</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>17.500000</td>\n",
       "      <td>63.388889</td>\n",
       "      <td>6.731579</td>\n",
       "      <td>1016.947368</td>\n",
       "      <td>16.083333</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>16.083333</td>\n",
       "      <td>64.541667</td>\n",
       "      <td>6.420833</td>\n",
       "      <td>1018.083333</td>\n",
       "      <td>17.857143</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>17.857143</td>\n",
       "      <td>56.095238</td>\n",
       "      <td>10.414286</td>\n",
       "      <td>1017.428571</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>19.800000</td>\n",
       "      <td>48.533333</td>\n",
       "      <td>15.926667</td>\n",
       "      <td>1015.200000</td>\n",
       "      <td>18.050000</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>18.050000</td>\n",
       "      <td>54.300000</td>\n",
       "      <td>19.404762</td>\n",
       "      <td>1015.619048</td>\n",
       "      <td>17.285714</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>17.285714</td>\n",
       "      <td>57.857143</td>\n",
       "      <td>6.180952</td>\n",
       "      <td>1016.142857</td>\n",
       "      <td>15.550000</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>15.550000</td>\n",
       "      <td>74.700000</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>1014.250000</td>\n",
       "      <td>17.318182</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>17.318182</td>\n",
       "      <td>78.636364</td>\n",
       "      <td>5.236364</td>\n",
       "      <td>1011.318182</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>94.300000</td>\n",
       "      <td>9.085000</td>\n",
       "      <td>1014.350000</td>\n",
       "      <td>17.142857</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>17.142857</td>\n",
       "      <td>74.857143</td>\n",
       "      <td>8.784211</td>\n",
       "      <td>1016.952381</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>16.850000</td>\n",
       "      <td>67.550000</td>\n",
       "      <td>8.335000</td>\n",
       "      <td>1017.200000</td>\n",
       "      <td>17.217391</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>17.217391</td>\n",
       "      <td>68.043478</td>\n",
       "      <td>3.547826</td>\n",
       "      <td>1015.565217</td>\n",
       "      <td>15.238095</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>15.238095</td>\n",
       "      <td>87.857143</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1016.904762</td>\n",
       "      <td>14.095238</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>14.095238</td>\n",
       "      <td>89.666667</td>\n",
       "      <td>6.266667</td>\n",
       "      <td>1017.904762</td>\n",
       "      <td>15.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>15.052632</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.325000</td>\n",
       "      <td>1016.100000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1461 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       meantemp   humidity  wind_speed  meanpressure    y_value  cday  year  \\\n",
       "0     10.000000  84.500000    0.000000   1015.666667   7.400000     1  2013   \n",
       "1      7.400000  92.000000    2.980000   1017.800000   7.166667     2  2013   \n",
       "2      7.166667  87.000000    4.633333   1018.666667   8.666667     3  2013   \n",
       "3      8.666667  71.333333    1.233333   1017.166667   6.000000     4  2013   \n",
       "4      6.000000  86.833333    3.700000   1016.500000   7.000000     5  2013   \n",
       "5      7.000000  82.800000    1.480000   1018.000000   7.000000     6  2013   \n",
       "6      7.000000  78.600000    6.300000   1020.000000   8.857143     0  2013   \n",
       "7      8.857143  63.714286    7.142857   1018.714286  14.000000     1  2013   \n",
       "8     14.000000  51.250000   12.500000   1017.000000  11.000000     2  2013   \n",
       "9     11.000000  62.000000    7.400000   1015.666667  15.714286     3  2013   \n",
       "10    15.714286  51.285714   10.571429   1016.142857  14.000000     4  2013   \n",
       "11    14.000000  74.000000   13.228571   1015.571429  15.833333     5  2013   \n",
       "12    15.833333  75.166667    4.633333   1013.333333  12.833333     6  2013   \n",
       "13    12.833333  88.166667    0.616667   1015.166667  14.714286     0  2013   \n",
       "14    14.714286  71.857143    0.528571   1015.857143  13.833333     1  2013   \n",
       "15    13.833333  86.666667    0.000000   1016.666667  16.500000     2  2013   \n",
       "16    16.500000  80.833333    5.250000   1015.833333  13.833333     3  2013   \n",
       "17    13.833333  92.166667    8.950000   1014.500000  12.500000     4  2013   \n",
       "18    12.500000  76.666667    5.883333   1021.666667  11.285714     5  2013   \n",
       "19    11.285714  75.285714    8.471429   1020.285714  11.200000     6  2013   \n",
       "20    11.200000  77.000000    2.220000   1021.000000   9.500000     0  2013   \n",
       "21     9.500000  79.666667    3.083333   1021.800000  14.000000     1  2013   \n",
       "22    14.000000  60.166667    4.016667   1020.500000  13.833333     2  2013   \n",
       "23    13.833333  60.666667    6.166667   1020.500000  12.250000     3  2013   \n",
       "24    12.250000  67.000000    5.550000   1020.750000  12.666667     4  2013   \n",
       "25    12.666667  64.166667    6.800000   1019.666667  12.857143     5  2013   \n",
       "26    12.857143  65.571429    5.557143   1018.142857  14.833333     6  2013   \n",
       "27    14.833333  56.000000    3.700000   1017.833333  14.125000     0  2013   \n",
       "28    14.125000  65.500000    3.237500   1016.625000  14.714286     1  2013   \n",
       "29    14.714286  70.428571    1.057143   1017.857143  16.200000     2  2013   \n",
       "...         ...        ...         ...           ...        ...   ...   ...   \n",
       "1431  19.208333  75.875000    4.945833   1017.750000  21.208333     4  2016   \n",
       "1432  21.208333  52.166667    5.866667   1019.333333  18.900000     5  2016   \n",
       "1433  18.900000  55.250000    5.666667   1019.700000  18.636364     6  2016   \n",
       "1434  18.636364  56.590909    4.952381   1017.045455  18.538462     0  2016   \n",
       "1435  18.538462  69.923077    2.503846   1017.961538  18.250000     1  2016   \n",
       "1436  18.250000  74.350000    0.925000   1017.421053  16.900000     2  2016   \n",
       "1437  16.900000  73.300000    1.765000   1016.200000  19.416667     3  2016   \n",
       "1438  19.416667  68.125000    1.312500   1013.416667  16.444444     4  2016   \n",
       "1439  16.444444  82.833333    5.355556   1014.000000  20.041667     5  2016   \n",
       "1440  20.041667  69.583333    4.716667   1013.291667  19.909091     6  2016   \n",
       "1441  19.909091  63.863636    3.281818   1014.181818  19.050000     0  2016   \n",
       "1442  19.050000  62.350000    3.430000   1015.100000  18.555556     1  2016   \n",
       "1443  18.555556  58.611111    8.027778   1017.333333  18.166667     2  2016   \n",
       "1444  18.166667  56.625000    9.879167   1016.666667  15.833333     3  2016   \n",
       "1445  15.833333  63.277778    3.916667   1018.777778  17.500000     4  2016   \n",
       "1446  17.500000  63.388889    6.731579   1016.947368  16.083333     5  2016   \n",
       "1447  16.083333  64.541667    6.420833   1018.083333  17.857143     6  2016   \n",
       "1448  17.857143  56.095238   10.414286   1017.428571  19.800000     0  2016   \n",
       "1449  19.800000  48.533333   15.926667   1015.200000  18.050000     1  2016   \n",
       "1450  18.050000  54.300000   19.404762   1015.619048  17.285714     2  2016   \n",
       "1451  17.285714  57.857143    6.180952   1016.142857  15.550000     3  2016   \n",
       "1452  15.550000  74.700000    1.205000   1014.250000  17.318182     4  2016   \n",
       "1453  17.318182  78.636364    5.236364   1011.318182  14.000000     5  2016   \n",
       "1454  14.000000  94.300000    9.085000   1014.350000  17.142857     6  2016   \n",
       "1455  17.142857  74.857143    8.784211   1016.952381  16.850000     0  2016   \n",
       "1456  16.850000  67.550000    8.335000   1017.200000  17.217391     1  2016   \n",
       "1457  17.217391  68.043478    3.547826   1015.565217  15.238095     2  2016   \n",
       "1458  15.238095  87.857143    6.000000   1016.904762  14.095238     3  2016   \n",
       "1459  14.095238  89.666667    6.266667   1017.904762  15.052632     4  2016   \n",
       "1460  15.052632  87.000000    7.325000   1016.100000  10.000000     5  2016   \n",
       "\n",
       "      month  season_fall  season_rainy  season_summer  season_winter  \n",
       "0         1            0             0              0              1  \n",
       "1         1            0             0              0              1  \n",
       "2         1            0             0              0              1  \n",
       "3         1            0             0              0              1  \n",
       "4         1            0             0              0              1  \n",
       "5         1            0             0              0              1  \n",
       "6         1            0             0              0              1  \n",
       "7         1            0             0              0              1  \n",
       "8         1            0             0              0              1  \n",
       "9         1            0             0              0              1  \n",
       "10        1            0             0              0              1  \n",
       "11        1            0             0              0              1  \n",
       "12        1            0             0              0              1  \n",
       "13        1            0             0              0              1  \n",
       "14        1            0             0              0              1  \n",
       "15        1            0             0              0              1  \n",
       "16        1            0             0              0              1  \n",
       "17        1            0             0              0              1  \n",
       "18        1            0             0              0              1  \n",
       "19        1            0             0              0              1  \n",
       "20        1            0             0              0              1  \n",
       "21        1            0             0              0              1  \n",
       "22        1            0             0              0              1  \n",
       "23        1            0             0              0              1  \n",
       "24        1            0             0              0              1  \n",
       "25        1            0             0              0              1  \n",
       "26        1            0             0              0              1  \n",
       "27        1            0             0              0              1  \n",
       "28        1            0             0              0              1  \n",
       "29        1            0             0              0              1  \n",
       "...     ...          ...           ...            ...            ...  \n",
       "1431     12            0             0              0              1  \n",
       "1432     12            0             0              0              1  \n",
       "1433     12            0             0              0              1  \n",
       "1434     12            0             0              0              1  \n",
       "1435     12            0             0              0              1  \n",
       "1436     12            0             0              0              1  \n",
       "1437     12            0             0              0              1  \n",
       "1438     12            0             0              0              1  \n",
       "1439     12            0             0              0              1  \n",
       "1440     12            0             0              0              1  \n",
       "1441     12            0             0              0              1  \n",
       "1442     12            0             0              0              1  \n",
       "1443     12            0             0              0              1  \n",
       "1444     12            0             0              0              1  \n",
       "1445     12            0             0              0              1  \n",
       "1446     12            0             0              0              1  \n",
       "1447     12            0             0              0              1  \n",
       "1448     12            0             0              0              1  \n",
       "1449     12            0             0              0              1  \n",
       "1450     12            0             0              0              1  \n",
       "1451     12            0             0              0              1  \n",
       "1452     12            0             0              0              1  \n",
       "1453     12            0             0              0              1  \n",
       "1454     12            0             0              0              1  \n",
       "1455     12            0             0              0              1  \n",
       "1456     12            0             0              0              1  \n",
       "1457     12            0             0              0              1  \n",
       "1458     12            0             0              0              1  \n",
       "1459     12            0             0              0              1  \n",
       "1460     12            0             0              0              1  \n",
       "\n",
       "[1461 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#procesamiento de fecha(datetime/timestamp) a numeros\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df['cday'] = df['date'].dt.dayofweek #0:lunes,6:domingo\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month #1:enero, 12: diciembre\n",
    "#based on: https://en.wikipedia.org/wiki/Climate_of_India\n",
    "seasons = [\"winter\",\"winter\",\"summer\",\"summer\",\"summer\",\"rainy\",\"rainy\",\"rainy\",\"fall\",\"fall\",\"fall\",\"winter\"]\n",
    "df['season'] = [ seasons[month_i - 1] for month_i in df['month'].values ]\n",
    "df = pd.get_dummies(df,columns=['season']) #to one hot.. as nominal variable\n",
    "#any more information?\n",
    "df.drop([\"date\"], axis=1, inplace=True) #delete date\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Cree las matrices de entrenamiento, con los mil primeros registros, y de validación, con el resto. Para evitar el orden natural en que vienen los datos entrenados, realice un *shuffle* aleatorio.\n",
    "```python\n",
    "y = df.pop(\"y_value\").values\n",
    "X = df.values \n",
    "X_train = X[:1000]\n",
    "y_train = y[:1000]\n",
    "X_val = X[1000:]\n",
    "y_val = y[1000:]\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0) #shuffle values on train only\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop(\"y_value\").values\n",
    "X = df.values \n",
    "X_train = X[:1000]\n",
    "y_train = y[:1000]\n",
    "X_val = X[1000:]\n",
    "y_val = y[1000:]\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0) #shuffle values on train only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a) Describa el problema trabajado, la cantida de datos que se cuenta como las características a trabajar. Al ser datos temporales podría ayudar una ilustración gráfica de la secuencias trabajadas y su comportamiento ¿Es válido el uso de la información sólo del día anterior?.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b) Entrene un solo Árbol de Regresión de múltiples niveles para resolver el problema. Defina un Árbol **no regularizado** (como el que no tiene límites en su profundidad) y otro Árbol **regularizado** (variando los hiper-parámetros que prefiera, por ejemplo, los más comunes como la profundidad, el número mínimo de datos para realizar *split* o el número mínimo de datos en cada hoja). Además comente sobre la ventaja de usar un árbol de decisión respecto a la escala de los datos ¿Porqué no es necesario escalar los datos?\n",
    "```python\n",
    "import numpy as np\n",
    "def RMSE(ytrue,ypred):\n",
    "    return np.sqrt(np.mean(np.square(ytrue - ypred)) )\n",
    "from sklearn.tree import DecisionTreeRegressor as Tree\n",
    "model_unr = Tree() #unregularized model -- default parameters\n",
    "model_unr.fit(X_train,y_train)\n",
    "... #define your regularized tree model\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8734665849026437"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def RMSE(ytrue,ypred):\n",
    "    return np.sqrt(np.mean(np.square(ytrue - ypred)) )\n",
    "from sklearn.tree import DecisionTreeRegressor as Tree\n",
    "model_unr = Tree() #unregularized model -- default parameters\n",
    "model_unr.fit(X_train,y_train)\n",
    "model_unr.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c) Para evaluar la calidad de predicción en este problema se utilizará la métrica *Root Mean Squared Error* (RMSE), indicando un error en la escala real de la temperatura. Como los datos de validación siguen con el orden temporal, visualice esa predicción a lo largo del tiempo. Comente sobre los resultados comparando la regularización *vs* el no regularizar.\n",
    "```python\n",
    "y_train_hat = model.predict(X_train)\n",
    "y_val_hat = model.predict(X_val)\n",
    "print(\"RMSE train= \",RMSE(y_train,y_train_hat))\n",
    "print(\"RMSE val= \",RMSE(y_val,y_val_hat))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(y_val, '.-' ,label=\"True values\")\n",
    "plt.plot(y_val_hat, '.-' ,label=\"Pred values\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train=  0.0\n",
      "RMSE val=  2.520333940817749\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_hat = model_unr.predict(X_train)\n",
    "y_val_hat = model_unr.predict(X_val)\n",
    "print(\"RMSE train= \",RMSE(y_train,y_train_hat))\n",
    "print(\"RMSE val= \",RMSE(y_val,y_val_hat))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(y_val, '.-' ,label=\"True values\")\n",
    "plt.plot(y_val_hat, '.-' ,label=\"Pred values\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> d) Entrene un ensamblado de árboles de múltiples niveles, mediante la técnica de **Bagging**, compare el Árbol **no regularizado** con el **regularizado** (*seteando los hiper-parámetros en base a lo experimentado anteriormente en b)*) ¿Qué debería suceder? ¿Se visualiza *overfitting*? Varíe la cantidad de árboles de decisión utilizados en el ensamblado (*n estimators*), realice un gráfico resumen del RMSE de entrenamiento y validación en función de este hiper-parámetro.\n",
    "```python\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "model = BaggingRegressor(base_estimator=Tree(...), n_estimators=..., n_jobs=-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e) Entrene un ensamblado de árboles de múltiples niveles, mediante la técnica de **AdaBoost**, compare el Árbol **no regularizado** con el **regularizado** (*seteando los hiper-parámetros en base a lo experimentado anteriormente en d)* ¿Se visualiza *overfitting*? ¿Qué técnica utiliza la librería de sklearn, *re-muestrear* o *pesar* ejemplos? ¿Qué le parece más sensato?. Varíe la cantidad de árboles de decisión utilizados en el ensamblado (*n estimators*), realice un gráfico resumen del RMSE de entrenamiento y validación en función de este hiper-parámetro. Compare y analice con la técnica utilizada en d).\n",
    "```python\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor(base_estimator=Tree(...), n_estimators=...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> f) Pruebe otra técnica de ensamblado dedicada a árboles de decisión, que combina el muestreo *boostrap* de *Bagging* con muestreo sobre las *features*: **Random Forest**, compare el Árbol **no regularizado** con el **regularizado** ¿Se visualiza *overfitting*?. Varíe la cantidad de árboles de decisión utilizados en el ensamblado (*n estimators*), realice un gráfico resumen del RMSE de entrenamiento y validación en función de este hiper-parámetro.\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_unr = RandomForestRegressor(n_estimators=..., n_jobs=-1)\n",
    "... #define your regularized random forest model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> g) Verifique que el **OOB error** (*out of bag error*) de los ensambladores que utilizan la técnica *boostrap* puede ser una alternativa como métrica de generalización, compare con el error calculado sobre el conjunto de validación (o en su defecto *cross validation*).\n",
    "```python\n",
    "oob_error = model.oob_score_\n",
    "val_error = model.score(X_val,y_val)\n",
    "print(\"OOB error: \",oob_error)\n",
    "print (\"Val error: \",val_error)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> h) Defina otra forma de combinar los valores que entregan los ensamblados al hacer predicciones y compare con lo que se hace actualmente, por ejemplo *Bagging* realiza el voto de la mayoría para clasificación y promedio para regresión, *AdaBoost* realiza una combinación ponderada de cada clasificador dependiendo de su *habilidad* (desempeño para clasificar el conjunto de entrenamiento). Se puede inspirar desde clásicos estadísticos, como entregar el primer cuartíl ($Q_1$) si al ensamblado le cuesta predecir valores bajos, o el segundo cuartil ($Q_2$) o mediana para ser robusto a predicciones atípicas de modelos.  \n",
    "```python\n",
    "def combine_predictions(predictions):\n",
    "    return #define !\n",
    "list_estimators = model.estimators_\n",
    "list_predictions = [estimator.predict(X_val) for estimator in list_estimators]\n",
    "new_predictions = combine_predictions(list_predictions)\n",
    "print(\"RMSE val= \",RMSE(y_val, new_predictions))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> i) Si se cuenta con una gran cantidad de modelos en el ensamblado, por ejemplo $T>100$, se puede crear un intervalo de confianza de la predicción a través de todos estos valores, asumiendo una distribución Normal centrada en la media muestral de las predicciones, con desviación estándar muestral en las predicciones. El intervalo de confianza entrega más información que un único valor puntual de predicción. Visualice un intervalo de confianza al 95% de probabilidad en la predicción a lo largo de la serie de tiempo de validación, comente. Al asumir una distribución Normal, también puede explorar el tomar como predicción del ensamblado el muestreo sobre la distribución Normal creada entorno a los datos muestrales.\n",
    "```python\n",
    "X_val_est = np.vstack(list_predictions).T #has shape=(N_test, n_estimator), with n_estimator>100\n",
    "from scipy.stats import norm\n",
    "interv_val = []\n",
    "for n in range(X_val.shape[0]):\n",
    "    low, up = norm.interval(0.95, loc=np.mean(X_val_est[n]), scale=np.std(X_val_est[n]))\n",
    "    interv_val.append([low,up])\n",
    "interv_val = np.asarray(interv_val)\n",
    "x = np.arange(X_val_est.shape[0])\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(x, np.mean(X_val_est, axis=1))\n",
    "plt.fill_between(x, interv_val[:,0], interv_val[:,1], color='r', alpha=.55)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  j) Evalúe y visualice la predicción del mejor modelo encontrado para resolver este problema, en el conjunto de pruebas. Además, compare y analice las distintas maneras con las que se resolvió el problema, incluya las decisiones que conlleva y los resultados que reflejan.\n",
    "```python\n",
    "df = pd.read_csv(\"DailyDelhiClimateTest.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"segundo\"></a>\n",
    "## 2. Detección de acoso en *Twitter*\n",
    "---\n",
    "En las redes sociales muchas veces se encuentra con un cierto comportamiento indeseable para los usuarios, tal como racismo, misógeno, grupos de odio o *trolls*. El poder detectar de manera automática ciertos patrones en el comportamiento para tomar una acción debe ser crucial para reducir el tiempo y esfuerzo humano. En esta actividad se trabajará sobre *tweets* la red social de *twitter* para detectar comportamiento *online* de acoso (*harassment*), que por lo general, incluye *flaming* como lenguaje abusivo o insultos, *doxing* como mostrar la información personal de una mujer, por ejemplo el domicilio o número de teléfono, la suplantación o la vergüenza pública por destruir la reputación de las personas.\n",
    "\n",
    "<img src=\"https://kidshelpline.com.au/sites/default/files/bdl_image/header-T-OH.png\" title=\"Title text\" width=\"45%\"  />\n",
    "\n",
    "En algunos problemas como este, el comportamiento a detectar puede ser asociado a una anomalía (*outlier*) del comportamiento normal de los usuarios en las redes sociales. Esto es una de las causas de la dificultad del problema, puesto que es **altamente desbalanceado**, donde aproximadamente un 10% de los *tweets* corresponden a acoso (*harassment*).\n",
    "\n",
    "Los datos trabajados corresponderan a *tweets* etiquetados como *harassment* (con valor 1) o no (con valor 0) -- la tarea a detectar--. Además si desea utilizar, se incluye la información del tipo de *harassment* en el conjunto de entrenamiento como atributos extras. El conjunto de pruebas solo contiene los *tweets* a ser etiquetados.\n",
    "\n",
    "---\n",
    "### Importante\n",
    "* Esta pregunta será evaluada **sólo** por los resultados (*submission*) obtenidos en el desafío presentado en __[Kaggle](https://www.kaggle.com/c/t1-ml/)__ a través del siguiente __[link](https://www.kaggle.com/t/91f8c0c746f945cfa510b88469df4d67)__. Las notas serán entregadas a través de la siguiente fórmula:  \n",
    "$$ Nota(i) = 100\\cdot max\\left(0.55; s^{(1-i)} \\right), \\ \\ con \\ \\ i \\in \\{1,\\ \\ldots, N\\}$$\n",
    "Con la escala de decaimiento es $ s = 1.05$ y con $i$ su lugar en el *ranking*.\n",
    "\n",
    "* La métrica de evaluación será el *f1 score* [[3]](#refs) sobre la clase positiva (*harassment*), así evaluar la calidad del modelo sobre la clase minoritaria, lo cual también debiera reflejar el desempeño de la clase negativa (al ser el complemento).\n",
    "```python\n",
    "from  sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred, average='binary')\n",
    "```\n",
    "\n",
    "* El archivo de *submission* debe contener las predicciones de *harassment* (0 o 1) a cada dato de pruebas, además de la columna de *id* asociado al dato, iniciando en 1. Si leyó de manera ordenada el archivo de pruebas, se puede generar de la siguiente manera:\n",
    "```python\n",
    "df_aux = pd.DataFrame()\n",
    "df_aux[\"id\"] = np.arange(1, 1+y_pred.shape[0])\n",
    "df_aux[\"harassment\"] = y_pred.astype('int')\n",
    "df_aux.to_csv(\"test_estimation.csv\", index=False)\n",
    "```\n",
    "\n",
    "* Se solicita realizar **un solo** *submission* por grupo, para no perjudicar la nota de sus compañeros en el *ranking*. Además de ser claros con sus nombres de entrega para no asignarles de manera errónea su correspondiente nota.\n",
    "\n",
    "* **Si no realiza *submission* a Kaggle su nota en esta sección será de 0**.\n",
    "\n",
    "* **Si su *score* alcanzado es menor o igual al *benchmark* random que se encuentra en el *ranking*, su nota en esta sección será de 25**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Test Set\n",
    "df_test = pd.read_csv(\"tarea3-ml/Test_input.csv\", encoding='ISO-8859-1')\n",
    "df_test_content = df_test.tweet_content\n",
    "y_test = pd.read_csv('tarea3-ml/sample_submission.csv')\n",
    "y_test = y_test.harassment\n",
    "#Train Set\n",
    "df_train = pd.read_csv(\"tarea3-ml/Train_data.csv\", encoding='ISO-8859-1')\n",
    "df_train = df_train.drop(columns=['id','IndirectH', 'PhysicalH', 'SexualH'])\n",
    "df_train_content = df_train.tweet_content\n",
    "labels_train = df_train.harassment\n",
    "\n",
    "tweet_by_harassment = df_train.groupby(['harassment']).count()\n",
    "plt.bar(['0','1'], tweet_by_harassment['tweet_content'], 0.35)\n",
    "plt.xlabel('Etiquetas')\n",
    "plt.ylabel('Nº Tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size_val_set = math.ceil(df_train.shape[0]*0.20)\n",
    "\n",
    "# df_train_content, df_val_content, labels_train, labels_val  = train_test_split(df_train_content, labels_train, \n",
    "#                                                                          test_size= size_val_set, random_state=0)\n",
    "# print(f'Train data size {df_train_content.shape[0]}')\n",
    "# print(f'Validation data size {df_val_content.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only harassment tweets\n",
    "df_only_harassment = df_train[df_train['harassment'] == 1]\n",
    "df_only_harassment = df_only_harassment['tweet_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de comentarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, time\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "\n",
    "def base_word(word):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    return wordlemmatizer.lemmatize(word) \n",
    "def word_extractor(text_input):\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text_input) #substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ base_word(word.lower()) for word in word_tokenize(text) ]\n",
    "    \n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords: #and len(word)>3:  #delete stopwords and emogis\n",
    "            words+=\" \"+word\n",
    "    if len(words) == 0:\n",
    "        print(text_input)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentar el uso de modismos y acronimos cortos de insulto; no filtrar estas palabras deberia ser mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_train = [word_extractor(tweet) for tweet in df_train_content]\n",
    "#content_val = [word_extractor(tweet) for tweet in df_val_content]\n",
    "content_test = [word_extractor(tweet) for tweet in df_test_content]\n",
    "harassment_tweets = [word_extractor(tweet) for tweet in df_only_harassment]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representación Term Frecuency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5703, 14863)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer= CountVectorizer(ngram_range=(1, 1), binary=False)\n",
    "vectorizer.fit(content_train)\n",
    "\n",
    "features_train = vectorizer.transform(content_train)\n",
    "#features_val = vectorizer.transform(content_val)\n",
    "features_test = vectorizer.transform(content_test)\n",
    "\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.78      0.62       899\n",
      "           1       0.52      0.24      0.33       886\n",
      "\n",
      "    accuracy                           0.51      1785\n",
      "   macro avg       0.51      0.51      0.47      1785\n",
      "weighted avg       0.51      0.51      0.47      1785\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3269082498072475"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from  sklearn.metrics import f1_score\n",
    "from imblearn.ensemble import BalancedBaggingClassifier # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def do_LOGIT(x,y,xv,yv, param):\n",
    "    #print(\"Param C= \",param)\n",
    "    model= LogisticRegression()\n",
    "    model.set_params(penalty='l2',C=param)\n",
    "    model.fit(x,y)\n",
    "    train_acc = model.score(x,y)\n",
    "    test_acc = model.score(xv,yv)\n",
    "    return model, train_acc, test_acc\n",
    "\n",
    "# model, train_acc, test_acc = do_LOGIT(features_train, labels_train, features_val, labels_val, param = 1)\n",
    "# train_acc, test_acc\n",
    "# model.score(features_test, y_test)\n",
    "#model = BaggingClassifier(base_estimator=LogisticRegression(penalty='l2', C=200), n_estimators=20).fit(features_train, labels_train)\n",
    "model = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=20)\n",
    "model.fit(features_train, labels_train)\n",
    "y_pred = model.predict(features_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "f1_score(y_test, y_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22605694564279552"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "underSampling = NearMiss(n_neighbors=10, version=2)\n",
    "X_train_res, y_train_res = underSampling.fit_sample(features_train, labels_train)\n",
    "\n",
    "model = BaggingClassifier(base_estimator=LogisticRegression(penalty='l2',C=10), n_estimators=20, n_jobs=-1).fit(X_train_res, y_train_res)\n",
    "y_pred = model.predict(features_test)\n",
    "f1_score(y_test, y_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10308, 2417)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.59      0.54       899\n",
      "           1       0.50      0.42      0.46       886\n",
      "\n",
      "    accuracy                           0.50      1785\n",
      "   macro avg       0.50      0.50      0.50      1785\n",
      "weighted avg       0.50      0.50      0.50      1785\n",
      "\n",
      "Acc: 0.5042016806722689\n",
      "f1-score: 0.4580526638089406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "os_us = SMOTETomek()\n",
    "X_train_smote, y_train_smote = os_us.fit_sample(features_train, labels_train)\n",
    "print(X_train_os.shape)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10)#max_depth=10\n",
    "rf_model.fit(X_train_smote, y_train_smote)\n",
    "y_pred = rf_model.predict(features_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Acc: {rf_model.score(features_test, y_test)}')\n",
    "print(f'f1-score: {f1_score(y_test, y_pred, average=\"binary\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6377759607522485"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BaggingClassifier(base_estimator=SVC(kernel='linear', C=0.001), n_estimators=100, n_jobs=-1)\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "y_pred = model.predict(features_test)\n",
    "f1_score(y_test, y_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.69      0.59       899\n",
      "           1       0.50      0.32      0.39       886\n",
      "\n",
      "    accuracy                           0.51      1785\n",
      "   macro avg       0.51      0.51      0.49      1785\n",
      "weighted avg       0.51      0.51      0.49      1785\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5064425770308123"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "model.score(features_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "termino\n"
     ]
    }
   ],
   "source": [
    "df_aux = pd.DataFrame()\n",
    "df_aux[\"id\"] = np.arange(1, 1+y_pred.shape[0])\n",
    "df_aux[\"harassment\"] = y_pred.astype('int')\n",
    "df_aux.to_csv(\"test_estimation3.csv\", index=False)\n",
    "print('termino')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "EMBEDDING_DIM = 300\n",
    "GLOVE_FILE = f\"glove/glove.6B.{EMBEDDING_DIM}d.txt\"\n",
    "embeddings_index = {}\n",
    "with open(GLOVE_FILE, encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_columns(sentences_vector):\n",
    "    c = 0\n",
    "    list_aux = []\n",
    "    matrix_n = np.empty((0,0))\n",
    "    for row in sentences_vector:\n",
    "        matrix = np.empty((0,0))\n",
    "#         print(\"2***********************\")\n",
    "        for word in row.split():\n",
    "#             print('***************************************************************************')\n",
    "            embd = embeddings_index.get(word)\n",
    "#             if embd is not None:\n",
    "#                 print(f'embd:{embd}')\n",
    "            if embd is None:\n",
    "                embd = np.zeros(300)\n",
    "                matrix = embd[np.newaxis,:] if matrix.shape == (0,0) else np.concatenate((matrix, embd[np.newaxis,:]), axis = 0)       \n",
    "            else:\n",
    "                matrix = embd[np.newaxis,:] if matrix.shape == (0,0) else np.concatenate((matrix,embd[np.newaxis,:]), axis = 0)\n",
    "#         print(f'matrix: {matrix} fin matrix')\n",
    "#         print(f'row: {rows}')\n",
    "        word_caracs = 0\n",
    "        if len(row) == 0:\n",
    "            word_caracs = np.zeros(300)\n",
    "        else:\n",
    "            word_caracs = matrix.mean(0)\n",
    "        matrix_n = word_caracs[np.newaxis,:] if matrix_n.shape == (0,0) else np.concatenate((matrix_n, word_caracs[np.newaxis,:]),\n",
    "                                                                                            axis = 0)\n",
    "        c+=1     \n",
    "    new_df = pd.DataFrame(list_aux)\n",
    "    return matrix_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_feature = generate_columns(content_train)\n",
    "#Val_feature = generate_columns(content_val)\n",
    "Test_feature = generate_columns(content_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "underSampling = NearMiss(n_neighbors=3, version=2)\n",
    "X_train_res, y_train_res = underSampling.fit_sample(Train_feature, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.13      0.21       899\n",
      "           1       0.50      0.86      0.63       886\n",
      "\n",
      "    accuracy                           0.50      1785\n",
      "   macro avg       0.50      0.50      0.42      1785\n",
      "weighted avg       0.50      0.50      0.42      1785\n",
      "\n",
      "Acc: 0.49523809523809526\n",
      "f1-score: 0.6296752979860255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=20, max_depth=10)#max_depth=10\n",
    "rf_model.fit(X_train_res, y_train_res)\n",
    "y_pred = rf_model.predict(Test_feature)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Acc: {rf_model.score(Test_feature, y_test)}')\n",
    "print(f'f1-score: {f1_score(y_test, y_pred, average=\"binary\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "termino\n"
     ]
    }
   ],
   "source": [
    "df_aux = pd.DataFrame()\n",
    "df_aux[\"id\"] = np.arange(1, 1+y_pred.shape[0])\n",
    "df_aux[\"harassment\"] = y_pred.astype('int')\n",
    "df_aux.to_csv(\"test_estimation.csv\", index=False)\n",
    "print('termino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.41      0.45       899\n",
      "           1       0.49      0.59      0.54       886\n",
      "\n",
      "    accuracy                           0.50      1785\n",
      "   macro avg       0.50      0.50      0.49      1785\n",
      "weighted avg       0.50      0.50      0.49      1785\n",
      "\n",
      "Acc: 0.49747899159663866\n",
      "f1-score: 0.5383427689140504\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model = BaggingClassifier(base_estimator=LogisticRegression(penalty='l2',C=0.9), n_estimators=100, n_jobs=-1).fit(X_train_res, y_train_res)\n",
    "y_pred = model.predict(Test_feature)\n",
    "f1_score(y_test, y_pred, average='binary')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Acc: {model.score(Test_feature, y_test)}')\n",
    "print(f'f1-score: {f1_score(y_test, y_pred, average=\"binary\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "termino\n"
     ]
    }
   ],
   "source": [
    "df_aux = pd.DataFrame()\n",
    "df_aux[\"id\"] = np.arange(1, 1+y_pred.shape[0])\n",
    "df_aux[\"harassment\"] = y_pred.astype('int')\n",
    "df_aux.to_csv(\"test_estimation6.csv\", index=False)\n",
    "print('termino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.45      0.48       899\n",
      "           1       0.50      0.56      0.53       886\n",
      "\n",
      "    accuracy                           0.50      1785\n",
      "   macro avg       0.50      0.50      0.50      1785\n",
      "weighted avg       0.50      0.50      0.50      1785\n",
      "\n",
      "Acc: 0.6542170787304927\n",
      "f1-score: 0.528\n"
     ]
    }
   ],
   "source": [
    "model = BalancedBaggingClassifier(base_estimator=SVC(kernel='linear'), n_estimators=10)\n",
    "model.fit(X_train_res, y_train_res)\n",
    "y_pred = model.predict(Test_feature)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Acc: {model.score(Train_feature, labels_train)}')\n",
    "print(f'f1-score: {f1_score(y_test, y_pred, average=\"binary\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.40      0.45       899\n",
      "           1       0.49      0.59      0.54       886\n",
      "\n",
      "    accuracy                           0.50      1785\n",
      "   macro avg       0.50      0.50      0.49      1785\n",
      "weighted avg       0.50      0.50      0.49      1785\n",
      "\n",
      "Acc: 0.6484306505348062\n",
      "f1-score: 0.5362840967575914\n"
     ]
    }
   ],
   "source": [
    "model= LogisticRegression()\n",
    "model.set_params(penalty='l2', class_weight=\"balanced\")\n",
    "model.fit(X_train_res,y_train_res)\n",
    "\n",
    "y_pred = model.predict(Test_feature)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Acc: {model.score(Train_feature, labels_train)}')\n",
    "print(f'f1-score: {f1_score(y_test, y_pred, average=\"binary\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "termino\n"
     ]
    }
   ],
   "source": [
    "df_aux = pd.DataFrame()\n",
    "df_aux[\"id\"] = np.arange(1, 1+y_pred.shape[0])\n",
    "df_aux[\"harassment\"] = y_pred.astype('int')\n",
    "df_aux.to_csv(\"test_estimation5.csv\", index=False)\n",
    "print('termino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.74      0.60       899\n",
      "           1       0.49      0.25      0.33       886\n",
      "\n",
      "    accuracy                           0.50      1785\n",
      "   macro avg       0.50      0.50      0.46      1785\n",
      "weighted avg       0.50      0.50      0.47      1785\n",
      "\n",
      "Acc: 0.49523809523809526\n",
      "f1-score: 0.3303437967115097\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(base_estimator =LogisticRegression(penalty='l2',C=10), n_estimators=100, random_state=0)\n",
    "clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred = model.predict(Test_feature)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Acc: {clf.score(Test_feature, y_test)}')\n",
    "print(f'f1-score: {f1_score(y_test, y_pred, average=\"binary\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10308, 300)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "overSampling =  RandomOverSampler()\n",
    "X_train_os, y_train_os = overSampling.fit_sample(Train_feature, labels_train)\n",
    "X_train_os.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       899\n",
      "           1       0.43      0.00      0.01       886\n",
      "\n",
      "    accuracy                           0.50      1785\n",
      "   macro avg       0.47      0.50      0.34      1785\n",
      "weighted avg       0.47      0.50      0.34      1785\n",
      "\n",
      "Acc: 0.5030812324929972\n",
      "f1-score: 0.006718924972004479\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=20)#max_depth=10\n",
    "rf_model.fit(X_train_os, y_train_os)\n",
    "y_pred = rf_model.predict(Test_feature)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Acc: {rf_model.score(Test_feature, y_test)}')\n",
    "print(f'f1-score: {f1_score(y_test, y_pred, average=\"binary\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.75      0.60       899\n",
      "           1       0.49      0.24      0.33       886\n",
      "\n",
      "    accuracy                           0.50      1785\n",
      "   macro avg       0.50      0.50      0.46      1785\n",
      "weighted avg       0.50      0.50      0.46      1785\n",
      "\n",
      "Acc: 0.4991596638655462\n",
      "f1-score: 0.3257918552036199\n"
     ]
    }
   ],
   "source": [
    "model = BaggingClassifier(base_estimator=LogisticRegression(penalty='l2',C=0.0001), n_estimators=20, n_jobs=-1)\n",
    "model.fit(X_train_os, y_train_os)\n",
    "y_pred = model.predict(Test_feature)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Acc: {model.score(Test_feature, y_test)}')\n",
    "print(f'f1-score: {f1_score(y_test, y_pred, average=\"binary\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.71      0.59       899\n",
      "           1       0.49      0.28      0.36       886\n",
      "\n",
      "    accuracy                           0.50      1785\n",
      "   macro avg       0.50      0.50      0.47      1785\n",
      "weighted avg       0.50      0.50      0.47      1785\n",
      "\n",
      "Acc: 0.8576187971243205\n",
      "f1-score: 0.35775862068965514\n"
     ]
    }
   ],
   "source": [
    "model = BaggingClassifier(base_estimator=SVC(kernel='linear'), n_estimators=10)\n",
    "model.fit(X_train_os, y_train_os)\n",
    "y_pred = model.predict(Test_feature)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Acc: {model.score(Train_feature, labels_train)}')\n",
    "print(f'f1-score: {f1_score(y_test, y_pred, average=\"binary\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.72      0.59       899\n",
      "           1       0.50      0.28      0.36       886\n",
      "\n",
      "    accuracy                           0.50      1785\n",
      "   macro avg       0.50      0.50      0.47      1785\n",
      "weighted avg       0.50      0.50      0.48      1785\n",
      "\n",
      "Acc: 0.8378046642118183\n",
      "f1-score: 0.3550724637681159\n"
     ]
    }
   ],
   "source": [
    "model= LogisticRegression()\n",
    "model.set_params(penalty='l2', C=0.01)\n",
    "model.fit(X_train_os,y_train_os)\n",
    "\n",
    "y_pred = model.predict(Test_feature)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Acc: {model.score(Train_feature, labels_train)}')\n",
    "print(f'f1-score: {f1_score(y_test, y_pred, average=\"binary\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling + Smote-Tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.73      0.60       899\n",
      "           1       0.50      0.27      0.35       886\n",
      "\n",
      "    accuracy                           0.50      1785\n",
      "   macro avg       0.50      0.50      0.47      1785\n",
      "weighted avg       0.50      0.50      0.47      1785\n",
      "\n",
      "Acc: 0.8130808346484306\n",
      "f1-score: 0.34558823529411764\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek # doctest: +NORMALIZE_WHITESPACE\n",
    "\n",
    "os_us = SMOTETomek()\n",
    "X_train_smote, y_train_smote = os_us.fit_sample(Train_feature, labels_train)\n",
    "\n",
    "model = BaggingClassifier(base_estimator=LogisticRegression(penalty='l2', C=0.001), n_estimators=10)\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "y_pred = model.predict(Test_feature)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Acc: {model.score(Train_feature, labels_train)}')\n",
    "print(f'f1-score: {f1_score(y_test, y_pred, average=\"binary\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.76      0.61       899\n",
      "           1       0.52      0.26      0.35       886\n",
      "\n",
      "    accuracy                           0.51      1785\n",
      "   macro avg       0.51      0.51      0.48      1785\n",
      "weighted avg       0.51      0.51      0.48      1785\n",
      "\n",
      "Acc: 0.8637559179379274\n",
      "f1-score: 0.34632683658170915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\castillo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model= LogisticRegression()\n",
    "model.set_params(penalty='l2', C=1)\n",
    "model.fit(X_train_smote,y_train_smote)\n",
    "\n",
    "y_pred = model.predict(Test_feature)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Acc: {model.score(Train_feature, labels_train)}')\n",
    "print(f'f1-score: {f1_score(y_test, y_pred, average=\"binary\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.97      0.66       899\n",
      "           1       0.47      0.03      0.06       886\n",
      "\n",
      "    accuracy                           0.50      1785\n",
      "   macro avg       0.49      0.50      0.36      1785\n",
      "weighted avg       0.49      0.50      0.36      1785\n",
      "\n",
      "Acc: 0.5019607843137255\n",
      "f1-score: 0.05726405090137858\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=20)#max_depth=10\n",
    "rf_model.fit(X_train_smote, y_train_smote)\n",
    "y_pred = rf_model.predict(Test_feature)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Acc: {rf_model.score(Test_feature, y_test)}')\n",
    "print(f'f1-score: {f1_score(y_test, y_pred, average=\"binary\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"refs\"></a>\n",
    "## Referencias\n",
    "[1] https://scikit-learn.org/stable/modules/ensemble.html  \n",
    "[2] https://scikit-learn.org/stable/modules/tree.html  \n",
    "[3] http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html  \n",
    "[4] https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "posibles mejoras:\n",
    "* Crear vocabulario de solo palabras que aparecen en los comentarios de acoso\n",
    "* quitar numeros y palabras con largo menor a o igual a 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
