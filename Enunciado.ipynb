{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-393 Máquinas de Aprendizaje II-2019 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 3 - Ensamblados y modelos avanzados </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "* Técnicas de ensamblado: *bagging*, *boosting* y *random forest*.\n",
    "* Ventajas de técnicas de ensamblados\n",
    "* Problemas desbalanceados\n",
    " \n",
    "\n",
    "**Formalidades**  \n",
    "* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
    "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
    "* Fecha de entrega y cierre competencia: 17 de Enero\n",
    "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea3-INF393-II-2019]\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Ensamblados para regresión  \n",
    "[2.](#segundo) Detección de acoso en *Twitter*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"primero\"></a>\n",
    "## 1. Ensamblados para regresión\n",
    "---\n",
    "Las técnicas de ensamblados vistos en clases pueden ser aplicadas tanto a problemas de clasificación o regresión, teniendo la ventaja de utilizar múltiples modelos de aprendizaje para utilizar la ventaja de cada uno. En este actividad se trabajará con predecir la temperatura media de un día, dada cierta información del día anterior, como la humedad, velocidad del viento, presión atmosférica, fecha y temperatura. El modelo predictor derivado puede ser bastante útil para conocer el comportamiento del clima a lo largo del tiempo.\n",
    "\n",
    "<img src=\"https://scijinks.gov/review/forecast-reliability/forecast-reliability2.jpg\" title=\"Title text\" width=\"70%\"  />\n",
    "\n",
    "Los datos de clima son recolectados en la ciudad Delhi de India por un período de 4 años (2013 a 2017), proporcionados en Kaggle a través del siguiente __[link](https://www.kaggle.com/sumanthvrao/daily-climate-time-series-data)__, las particiones de entrenamiento y prueba están dadas. El registro de cada dato corresponde a un día, incrementando a través de las filas por cada día.\n",
    "\n",
    "---\n",
    "    \n",
    ">  Cargue los datos en un dataframe de pandas, además agregue una columna indicando el valor a predecir, la temperatura media del día siguiente. *Como el último dato/registro no tiene un valor a predecir éste se elimina*.\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"DailyDelhiClimateTrain.csv\")\n",
    "df[\"y_value\"] = df[\"meantemp\"].shift(-1)\n",
    "df = df.iloc[:-1] #remove last row\n",
    "```\n",
    "\n",
    "> Debido a la poca información que se tiene a través de los 4 parámetros medidos, extraíga más información a través de los datos de fecha. Por ejemplo, el comportamiento a través de los meses y años varía, así como la información de la temporada del año podría ayudar a la predicción. Decida si puede incluir más información a partir de la fecha que tenga sentido con el problema.\n",
    "```python\n",
    "...#procesamiento de fecha(datetime/timestamp) a numeros\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df['cday'] = df['date'].dt.dayofweek #0:lunes,6:domingo\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month #1:enero, 12: diciembre\n",
    "...#based on: https://en.wikipedia.org/wiki/Climate_of_India\n",
    "seasons = [\"winter\",\"winter\",\"summer\",\"summer\",\"summer\",\"rainy\",\"rainy\",\"rainy\",\"fall\",\"fall\",\"fall\",\"winter\"]\n",
    "df['season'] = [ seasons[month_i - 1] for month_i in df['month'].values ]\n",
    "df = pd.get_dummies(df,columns=['season']) #to one hot.. as nominal variable\n",
    "... #any more information?\n",
    "df.drop([\"date\"], axis=1, inplace=True) #delete date\n",
    "```\n",
    "\n",
    "> Cree las matrices de entrenamiento, con los mil primeros registros, y de validación, con el resto. Para evitar el orden natural en que vienen los datos entrenados, realice un *shuffle* aleatorio.\n",
    "```python\n",
    "y = df.pop(\"y_value\").values\n",
    "X = df.values \n",
    "X_train = X[:1000]\n",
    "y_train = y[:1000]\n",
    "X_val = X[1000:]\n",
    "y_val = y[1000:]\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0) #shuffle values on train only\n",
    "```\n",
    "\n",
    "> a) Describa el problema trabajado, la cantida de datos que se cuenta como las características a trabajar. Al ser datos temporales podría ayudar una ilustración gráfica de la secuencias trabajadas y su comportamiento ¿Es válido el uso de la información sólo del día anterior?.\n",
    "\n",
    "\n",
    "> b) Entrene un solo Árbol de Regresión de múltiples niveles para resolver el problema. Defina un Árbol **no regularizado** (como el que no tiene límites en su profundidad) y otro Árbol **regularizado** (variando los hiper-parámetros que prefiera, por ejemplo, los más comunes como la profundidad, el número mínimo de datos para realizar *split* o el número mínimo de datos en cada hoja). Además comente sobre la ventaja de usar un árbol de decisión respecto a la escala de los datos ¿Porqué no es necesario escalar los datos?\n",
    "```python\n",
    "import numpy as np\n",
    "def RMSE(ytrue,ypred):\n",
    "    return np.sqrt(np.mean(np.square(ytrue - ypred)) )\n",
    "from sklearn.tree import DecisionTreeRegressor as Tree\n",
    "model_unr = Tree() #unregularized model -- default parameters\n",
    "model_unr.fit(X_train,y_train)\n",
    "... #define your regularized tree model\n",
    "``` \n",
    "\n",
    "> c) Para evaluar la calidad de predicción en este problema se utilizará la métrica *Root Mean Squared Error* (RMSE), indicando un error en la escala real de la temperatura. Como los datos de validación siguen con el orden temporal, visualice esa predicción a lo largo del tiempo. Comente sobre los resultados comparando la regularización *vs* el no regularizar.\n",
    "```python\n",
    "y_train_hat = model.predict(X_train)\n",
    "y_val_hat = model.predict(X_val)\n",
    "print(\"RMSE train= \",RMSE(y_train,y_train_hat))\n",
    "print(\"RMSE val= \",RMSE(y_val,y_val_hat))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(y_val, '.-' ,label=\"True values\")\n",
    "plt.plot(y_val_hat, '.-' ,label=\"Pred values\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "    \n",
    "> d) Entrene un ensamblado de árboles de múltiples niveles, mediante la técnica de **Bagging**, compare el Árbol **no regularizado** con el **regularizado** (*seteando los hiper-parámetros en base a lo experimentado anteriormente en b)*) ¿Qué debería suceder? ¿Se visualiza *overfitting*? Varíe la cantidad de árboles de decisión utilizados en el ensamblado (*n estimators*), realice un gráfico resumen del RMSE de entrenamiento y validación en función de este hiper-parámetro.\n",
    "```python\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "model = BaggingRegressor(base_estimator=Tree(...), n_estimators=..., n_jobs=-1)\n",
    "```\n",
    "\n",
    "> e) Entrene un ensamblado de árboles de múltiples niveles, mediante la técnica de **AdaBoost**, compare el Árbol **no regularizado** con el **regularizado** (*seteando los hiper-parámetros en base a lo experimentado anteriormente en d)* ¿Se visualiza *overfitting*? ¿Qué técnica utiliza la librería de sklearn, *re-muestrear* o *pesar* ejemplos? ¿Qué le parece más sensato?. Varíe la cantidad de árboles de decisión utilizados en el ensamblado (*n estimators*), realice un gráfico resumen del RMSE de entrenamiento y validación en función de este hiper-parámetro. Compare y analice con la técnica utilizada en d).\n",
    "```python\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor(base_estimator=Tree(...), n_estimators=...)\n",
    "```\n",
    "\n",
    "> f) Pruebe otra técnica de ensamblado dedicada a árboles de decisión, que combina el muestreo *boostrap* de *Bagging* con muestreo sobre las *features*: **Random Forest**, compare el Árbol **no regularizado** con el **regularizado** ¿Se visualiza *overfitting*?. Varíe la cantidad de árboles de decisión utilizados en el ensamblado (*n estimators*), realice un gráfico resumen del RMSE de entrenamiento y validación en función de este hiper-parámetro.\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_unr = RandomForestRegressor(n_estimators=..., n_jobs=-1)\n",
    "... #define your regularized random forest model\n",
    "```\n",
    "\n",
    "> g) Verifique que el **OOB error** (*out of bag error*) de los ensambladores que utilizan la técnica *boostrap* puede ser una alternativa como métrica de generalización, compare con el error calculado sobre el conjunto de validación (o en su defecto *cross validation*).\n",
    "```python\n",
    "oob_error = model.oob_score_\n",
    "val_error = model.score(X_val,y_val)\n",
    "print(\"OOB error: \",oob_error)\n",
    "print (\"Val error: \",val_error)\n",
    "```\n",
    "\n",
    "> h) Defina otra forma de combinar los valores que entregan los ensamblados al hacer predicciones y compare con lo que se hace actualmente, por ejemplo *Bagging* realiza el voto de la mayoría para clasificación y promedio para regresión, *AdaBoost* realiza una combinación ponderada de cada clasificador dependiendo de su *habilidad* (desempeño para clasificar el conjunto de entrenamiento). Se puede inspirar desde clásicos estadísticos, como entregar el primer cuartíl ($Q_1$) si al ensamblado le cuesta predecir valores bajos, o el segundo cuartil ($Q_2$) o mediana para ser robusto a predicciones atípicas de modelos.  \n",
    "```python\n",
    "def combine_predictions(predictions):\n",
    "    return #define !\n",
    "list_estimators = model.estimators_\n",
    "list_predictions = [estimator.predict(X_val) for estimator in list_estimators]\n",
    "new_predictions = combine_predictions(list_predictions)\n",
    "print(\"RMSE val= \",RMSE(y_val, new_predictions))\n",
    "```\n",
    "\n",
    "> i) Si se cuenta con una gran cantidad de modelos en el ensamblado, por ejemplo $T>100$, se puede crear un intervalo de confianza de la predicción a través de todos estos valores, asumiendo una distribución Normal centrada en la media muestral de las predicciones, con desviación estándar muestral en las predicciones. El intervalo de confianza entrega más información que un único valor puntual de predicción. Visualice un intervalo de confianza al 95% de probabilidad en la predicción a lo largo de la serie de tiempo de validación, comente. Al asumir una distribución Normal, también puede explorar el tomar como predicción del ensamblado el muestreo sobre la distribución Normal creada entorno a los datos muestrales.\n",
    "```python\n",
    "X_val_est = np.vstack(list_predictions).T #has shape=(N_test, n_estimator), with n_estimator>100\n",
    "from scipy.stats import norm\n",
    "interv_val = []\n",
    "for n in range(X_val.shape[0]):\n",
    "    low, up = norm.interval(0.95, loc=np.mean(X_val_est[n]), scale=np.std(X_val_est[n]))\n",
    "    interv_val.append([low,up])\n",
    "interv_val = np.asarray(interv_val)\n",
    "x = np.arange(X_val_est.shape[0])\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(x, np.mean(X_val_est, axis=1))\n",
    "plt.fill_between(x, interv_val[:,0], interv_val[:,1], color='r', alpha=.55)\n",
    "plt.show()\n",
    "```\n",
    "    \n",
    ">  j) Evalúe y visualice la predicción del mejor modelo encontrado para resolver este problema, en el conjunto de pruebas. Además, compare y analice las distintas maneras con las que se resolvió el problema, incluya las decisiones que conlleva y los resultados que reflejan.\n",
    "```python\n",
    "df = pd.read_csv(\"DailyDelhiClimateTest.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"segundo\"></a>\n",
    "## 2. Detección de acoso en *Twitter*\n",
    "---\n",
    "En las redes sociales muchas veces se encuentra con un cierto comportamiento indeseable para los usuarios, tal como racismo, misógeno, grupos de odio o *trolls*. El poder detectar de manera automática ciertos patrones en el comportamiento para tomar una acción debe ser crucial para reducir el tiempo y esfuerzo humano. En esta actividad se trabajará sobre *tweets* la red social de *twitter* para detectar comportamiento *online* de acoso (*harassment*), que por lo general, incluye *flaming* como lenguaje abusivo o insultos, *doxing* como mostrar la información personal de una mujer, por ejemplo el domicilio o número de teléfono, la suplantación o la vergüenza pública por destruir la reputación de las personas.\n",
    "\n",
    "<img src=\"https://kidshelpline.com.au/sites/default/files/bdl_image/header-T-OH.png\" title=\"Title text\" width=\"45%\"  />\n",
    "\n",
    "En algunos problemas como este, el comportamiento a detectar puede ser asociado a una anomalía (*outlier*) del comportamiento normal de los usuarios en las redes sociales. Esto es una de las causas de la dificultad del problema, puesto que es **altamente desbalanceado**, donde aproximadamente un 10% de los *tweets* corresponden a acoso (*harassment*).\n",
    "\n",
    "Los datos trabajados corresponderan a *tweets* etiquetados como *harassment* (con valor 1) o no (con valor 0) -- la tarea a detectar--. Además si desea utilizar, se incluye la información del tipo de *harassment* en el conjunto de entrenamiento como atributos extras. El conjunto de pruebas solo contiene los *tweets* a ser etiquetados.\n",
    "\n",
    "---\n",
    "### Importante\n",
    "* Esta pregunta será evaluada **sólo** por los resultados (*submission*) obtenidos en el desafío presentado en __[Kaggle](https://www.kaggle.com/c/t1-ml/)__ a través del siguiente __[link](https://www.kaggle.com/t/91f8c0c746f945cfa510b88469df4d67)__. Las notas serán entregadas a través de la siguiente fórmula:  \n",
    "$$ Nota(i) = 100\\cdot max\\left(0.55; s^{(1-i)} \\right), \\ \\ con \\ \\ i \\in \\{1,\\ \\ldots, N\\}$$\n",
    "Con la escala de decaimiento es $ s = 1.05$ y con $i$ su lugar en el *ranking*.\n",
    "\n",
    "* La métrica de evaluación será el *f1 score* [[3]](#refs) sobre la clase positiva (*harassment*), así evaluar la calidad del modelo sobre la clase minoritaria, lo cual también debiera reflejar el desempeño de la clase negativa (al ser el complemento).\n",
    "```python\n",
    "from  sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred, average='binary')\n",
    "```\n",
    "\n",
    "* El archivo de *submission* debe contener las predicciones de *harassment* (0 o 1) a cada dato de pruebas, además de la columna de *id* asociado al dato, iniciando en 1. Si leyó de manera ordenada el archivo de pruebas, se puede generar de la siguiente manera:\n",
    "```python\n",
    "df_aux = pd.DataFrame()\n",
    "df_aux[\"id\"] = np.arange(1, 1+y_pred.shape[0])\n",
    "df_aux[\"harassment\"] = y_pred.astype('int')\n",
    "df_aux.to_csv(\"test_estimation.csv\", index=False)\n",
    "```\n",
    "\n",
    "* Se solicita realizar **un solo** *submission* por grupo, para no perjudicar la nota de sus compañeros en el *ranking*. Además de ser claros con sus nombres de entrega para no asignarles de manera errónea su correspondiente nota.\n",
    "\n",
    "* **Si no realiza *submission* a Kaggle su nota en esta sección será de 0**.\n",
    "\n",
    "* **Si su *score* alcanzado es menor o igual al *benchmark* random que se encuentra en el *ranking*, su nota en esta sección será de 25**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"refs\"></a>\n",
    "## Referencias\n",
    "[1] https://scikit-learn.org/stable/modules/ensemble.html  \n",
    "[2] https://scikit-learn.org/stable/modules/tree.html  \n",
    "[3] http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html  \n",
    "[4] https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
